Sample 70 rows from attrition_pop using simple random sampling, setting the random seed to 18900217.
Print the sample dataset, attrition_samp. What do you notice about the indices?

# Sample 70 rows using simple random sampling and set the seed
attrition_samp = attrition_pop.sample(n=70, random_state=18900217)

# Print the sample
print(attrition_samp)


Set the sample size to 70.
Calculate the population size from attrition_pop.
Calculate the interval between the rows to be sampled.

# Set the sample size to 70
sample_size = attrition_pop.sample(n=70)
print(sample_size)

# Calculate the population size from attrition_pop
pop_size = len(attrition_pop)
print(pop_size)

# Calculate the interval
interval = pop_size // sample_size

Systematically sample attrition_pop to get the rows of the population at each interval, starting at 0; assign the rows to attrition_sys_samp.

# Systematically sample 70 rows
attrition_sys_samp = attrition_pop.iloc[::interval]

# Print the sample
print(attrition_sys_samp)


Add an index column to attrition_pop, assigning the result to attrition_pop_id.
Create a scatter plot of YearsAtCompany versus index for attrition_pop_id using pandas .plot().

# Add an index column to attrition_pop
attrition_pop_id = attrition_pop.reset_index()

# Plot YearsAtCompany vs. index for attrition_pop_id
attrition_pop_id.plot(x='index', y='YearsAtCompany', kind='scatter')
plt.show()

Randomly shuffle the rows of attrition_pop.
Reset the row indexes, and add an index column to attrition_pop.
Repeat the scatter plot of YearsAtCompany versus index, this time using attrition_shuffled.

# Shuffle the rows of attrition_pop
attrition_shuffled = attrition_pop.sample(frac=1)

# Reset the row indexes and create an index column
attrition_shuffled = attrition_shuffled.reset_index(drop=True).reset_index()

# Plot YearsAtCompany vs. index for attrition_shuffled
attrition_shuffled.plot(x='index', y='YearsAtCompany', kind='scatter')
plt.show()

Does a systematic sample always produce a sample similar to a simple random sample?

No. This is not true if the data is sorted in some way.'


Get the proportion of employees by Education level from attrition_pop.

# Proportion of employees by Education level
education_counts_pop = attrition_pop['Education'].value_counts(normalize=True)
# Print education_counts_pop
print(education_counts_pop)

Use proportional stratified sampling on attrition_pop to sample 40% of each Education group, setting the seed to 2022.

# Proportional stratified sampling for 40% of each Education group
attrition_strat = attrition_pop.groupby('Education').sample(frac=0.4, random_state=2022)

# Print the sample
print(attrition_strat)

Get the proportion of employees by Education level from attrition_strat.

# Proportional stratified sampling for 40% of each Education group
attrition_strat = attrition_pop.groupby('Education')\
  .sample(frac=0.4, random_state=2022)

# Calculate the Education level proportions from attrition_strat
education_counts_strat = attrition_strat['Education'].value_counts(normalize=True)

# Print education_counts_strat
print(education_counts_strat)


Use equal counts stratified sampling on attrition_pop to get 30 employees from each Education group, setting the seed to 2022.

# Get 30 employees from each Education group
attrition_eq = attrition_pop.groupby('Education').sample(n=30, random_state=2022)

# Print the sample
print(attrition_eq)

Get the proportion of employees by Education level from attrition_eq.

# Get 30 employees from each Education group
attrition_eq = attrition_pop.groupby('Education')\
	.sample(n=30, random_state=2022)      

# Get the proportions from attrition_eq
education_counts_eq = attrition_eq['Education'].value_counts(normalize=True)

# Print the results
print(education_counts_eq)


Plot YearsAtCompany from attrition_pop as a histogram with bins of width 1 from 0 to 40.

# Plot YearsAtCompany from attrition_pop as a histogram
attrition_pop['YearsAtCompany'].hist(bins=np.arange(0,41,1))
plt.show()

Sample 400 employees from attrition_pop weighted by YearsAtCompany.
# Sample 400 employees weighted by YearsAtCompany
attrition_weight = attrition_pop.sample(n=400, weights="YearsAtCompany")

# Print the sample
print(attrition_weight)

Plot YearsAtCompany from attrition_weight as a histogram with bins of width 1 from 0 to 40.

# Plot YearsAtCompany from attrition_weight as a histogram
attrition_weight['YearsAtCompany'].hist(bins= np.arange(0, 41, 1))
plt.show()

Which is higher? The mean YearsAtCompany from attrition_pop or the mean YearsAtCompany from attrition_weight?

Sample mean.


Cluster sampling is a two-stage sampling technique that is closely related to stratified sampling. First, you randomly sample which subgroups to include in the sample, then randomly sample rows within each subgroup.
In which of the following situations would cluster sampling be preferable to stratified sampling?

The interest is on ensuring each rare group will be represented in the sample selected.


Create a list of unique JobRole values from attrition_pop, and assign to job_roles_pop.
Randomly sample four JobRole values from job_roles_pop.

# Create a list of unique JobRole values
job_roles_pop = list(attrition_pop['JobRole'].unique())

# Randomly sample four JobRole values
job_roles_samp = random.sample(job_roles_pop, k=4)

# Print the result
print(job_roles_samp)

Subset attrition_pop for the sampled job roles by filtering for rows where JobRole is in job_roles_samp.

# Filter for rows where JobRole is in job_roles_samp
jobrole_condition = attrition_pop['JobRole'].isin(job_roles_samp)
attrition_filtered = attrition_pop[jobrole_condition]

# Print the result
print(attrition_filtered)

Remove any unused categories from JobRole.
For each job role in the filtered dataset, take a random sample of ten rows, setting the seed to 2022.

# Remove categories with no rows
attrition_filtered['JobRole'] = attrition_filtered['JobRole'].cat.remove_unused_categories()

# Randomly sample 10 employees from each sampled job role
attrition_clust = attrition_filtered.groupby('JobRole').sample(n=10, random_state=2022)

# Print the sample
print(attrition_clust)


Perform simple random sampling on attrition_pop to get one-quarter of the population, setting the seed to 2022.

# Perform simple random sampling to get 0.25 of the population
attrition_srs = attrition_pop.sample(frac=0.25, random_state=2022)

Perform stratified sampling on attrition_pop to sample one-quarter of each RelationshipSatisfaction group, setting the seed to 2022.

# Perform stratified sampling to get 0.25 of each relationship group
attrition_strat = attrition_pop['RelationshipSatisfaction'].sample(frac=0.25, random_state=2022)

Create a list of unique values from attrition_pop's RelationshipSatisfaction column.
Randomly sample satisfaction_unique to get two values.
Subset the population for rows where RelationshipSatisfaction is in satisfaction_samp and clear any unused categories from RelationshipSatisfaction; assign to attrition_clust_prep.
Perform cluster sampling on the selected satisfaction groups, sampling one quarter of the population and setting the seed to 2022.

# Create a list of unique RelationshipSatisfaction values
satisfaction_unique = list(attrition_pop['RelationshipSatisfaction'].unique())

# Randomly sample 2 unique satisfaction values
satisfaction_samp = random.sample(satisfaction_unique, k=2)

# Filter for satisfaction_samp and clear unused categories from RelationshipSatisfaction
satis_condition = attrition_pop['RelationshipSatisfaction'].isin(satisfaction_samp)
attrition_clust_prep = attrition_pop[satis_condition]
attrition_clust_prep['RelationshipSatisfaction'] = attrition_clust_prep['RelationshipSatisfaction'].cat.remove_unused_categories()

# Perform cluster sampling on the selected group, getting 0.25 of attrition_pop
attrition_clust = attrition_clust_prep.groupby('RelationshipSatisfaction')\
                    .sample(n= len(attrition_pop) // 4, random_state=2022)
         
         
Group attrition_pop by RelationshipSatisfaction levels and calculate the mean of Attrition for each level.

# Mean Attrition by RelationshipSatisfaction group
mean_attrition_pop = attrition_pop.groupby('RelationshipSatisfaction')['Attrition'].mean()

# Print the result
print(mean_attrition_pop)

Calculate the proportion of employee attrition for each relationship satisfaction group, this time on the simple random sample, attrition_srs.

# Calculate the same thing for the simple random sample 
mean_attrition_srs = attrition_srs.groupby('RelationshipSatisfaction')['Attrition'].mean()

# Print the result
print(mean_attrition_srs)

Calculate the proportion of employee attrition for each relationship satisfaction group, this time on the stratified sample, attrition_strat.

# Calculate the same thing for the stratified sample 
mean_attrition_strat = attrition_strat.groupby('RelationshipSatisfaction')['Attrition'].mean()

# Print the result
print(mean_attrition_strat)

Calculate the proportion of employee attrition for each relationship satisfaction group, this time on the cluster sample, attrition_clust

# Calculate the same thing for the cluster sample 
mean_attrition_clust = attrition_clust.groupby('RelationshipSatisfaction')['Attrition'].mean()

# Print the result
print(mean_attrition_clust)





